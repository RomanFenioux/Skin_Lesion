\documentclass[a4paper,10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{multirow}
\usepackage{subcaption}
\usepackage{notoccite}
%\usepackage{xargs}                      % Use more than one optional parameter in a new commands
%\usepackage[pdftex,dvipsnames]{xcolor}  % Coloured text etc.
\usepackage[colorinlistoftodos,prependcaption,textsize=tiny]{todonotes}
% note: disable any of the following commands by adding 'disable' as a first option after \todo
% see example below
%\newcommandx{\tobecompleted}[2][1=]{\todo[linecolor=red,backgroundcolor=red!25,
%	bordercolor=red,#1]{#2}}
%\newcommandx{\thiswillnotshow}[2][1=]{\todo[disable,linecolor=OliveGreen,
%	backgroundcolor=OliveGreen!25,bordercolor=OliveGreen,#1]{#2}}

\DeclareMathOperator*{\argmin}{argmin} 
\DeclareMathOperator*{\argmax}{argmax} 

%opening
\title{PRIM\\ Comparison of Segmentation Methods for Skin Lesions in Dermoscopy Images}
\author{Roman Fenioux}
\date{September 2017 - January 2018}

\begin{document}
\maketitle
\newpage
\section*{Introduction}
Dermoscopy is a technique used by dermatologist to examine skin lesion, in order to distinguish cancerous lesions, especially melanoma, from benign lesions. However, it is a tedious and challenging task for dermatologist because of the visual similarity between the types of lesions and the important variations of shape, color and texture. This lead to a significant intra and interpersonal variability and a diagnosis accuracy of only 60\%~\cite{kittler_diagnostic_2002}. An efficient computerized analysis of dermoscopy images represents therefore a huge benefice while providing more reproducibility in the results and quantitative information. Such methods have usually three main steps : segmentation, feature extraction and classification. Although recent methods based on deep neural network merge the feature extraction with the classification, they often still have a distinct segmentation stage. 

This project will focus on the segmentation stage, for which we will compare three methods based on different approaches : thresholding~\cite{Garnavi2010}, region growing~\cite{celebi_border_2008} and level set active contours~\cite{li2010distance}. Other methods include clustering~\cite{gomez_independent_2008}, edge operators, morphological watershed~\cite{schmid_lesion_1999}, model-based algorithms~\cite{gao_segmentation_1998} and soft computing~\cite{yu_automated_2017}.
Overview of the recent border detection methods has been conducted in 2009 by Celebi and al ~\cite{celebi_lesion_2009}.

\subsection*{Data}

The data used for this project are 42 images from the 2017 ISBI challenge "Skin Lesion Analysis Toward Melanoma Detection"~\cite{codella_skin_2017}. The sizes range from 538x720 to 2814x2110 pixels for an 8 bit encoding. Segmentation masks were created by an expert clinician, using either a semi-automated process (using a user-provided seed point, a user-tuned flood-fill algorithm, and morphological filtering) or a manual process (from a series of user-provided polyline points). 

\begin{figure}[h]
	
	\includegraphics[width=0.24\linewidth]{../results/data_examples/nev/ex-001.png} 
	\includegraphics[width=0.24\linewidth]{../results/data_examples/nev/ex-008.png}
	\includegraphics[width=0.24\linewidth]{../results/data_examples/mel/ex-013.png} 
	\includegraphics[width=0.24\linewidth]{../results/data_examples/mel/ex-026.png}\\
	\includegraphics[width=0.24\linewidth]{../results/data_examples/nev/ex-011.png} 
	\includegraphics[width=0.24\linewidth]{../results/data_examples/nev/ex-235.png}
	\includegraphics[width=0.24\linewidth]{../results/data_examples/mel/ex-049.png} 
	\includegraphics[width=0.24\linewidth]{../results/data_examples/mel/ex-031.png} \\
	\includegraphics[width=0.24\linewidth]{../results/data_examples/nev/ex-095.png} 
	\includegraphics[width=0.24\linewidth]{../results/data_examples/nev/ex-127.png} 
	\includegraphics[width=0.24\linewidth]{../results/data_examples/mel/ex-043.png} 
	\includegraphics[width=0.24\linewidth]{../results/data_examples/mel/ex-004.png}\\
	\caption{Example of data used with ground truth segmentation (green)}
	\label{fig:data_examples}
\end{figure}

Examples can be seen in figure \ref{fig:data_examples} and we can note the difference between the semi-automated method that closely follows the lesion borders as in the upper left image and the polyline method, purposed to contain all of the lesion area when border are fuzzy as in the top right image.

\subsection*{Problems with border detection}

\begin{figure}[h]
	\begin{subfigure}{0.32\linewidth}
		\includegraphics[width=0.99\linewidth]{../results/data_examples/035.jpg} 
		\caption{Fuzzy borders}
		\label{fig:fuzz}
	\end{subfigure}
	\begin{subfigure}{0.32\linewidth}
		\includegraphics[width=0.99\linewidth]{../results/data_examples/235.jpg} 
		\caption{Color variations}
		\label{fig:color-var}
	\end{subfigure}
	\begin{subfigure}{0.32\linewidth}
		\includegraphics[width=0.99\linewidth]{../results/data_examples/127.jpg} 
		\caption{Fragmentation}
		\label{fig:frag-pb}
	\end{subfigure}
	\begin{subfigure}{0.32\linewidth}
		\includegraphics[width=0.99\linewidth]{../results/data_examples/036.jpg} 
		\caption{Black frame}
		\label{fig:black-fr-pb}
	\end{subfigure}
	\begin{subfigure}{0.32\linewidth}
		\includegraphics[width=0.99\linewidth]{../results/data_examples/095.jpg} 
		\caption{Dark hair}
		\label{fig:hair-pb}
	\end{subfigure}
	\begin{subfigure}{0.32\linewidth}
		\includegraphics[width=0.99\linewidth]{../results/data_examples/026.jpg} 
		\caption{Low contrast}
		\label{fig:lowcontrast}
	\end{subfigure}	
	\caption{Most common problems encountered in lesion segmentation}
	\label{fig:seg_problems}
\end{figure}

The segmentation errors are often caused by two main reasons. The first is a problem of image quality such as the presence artifacts (hair and other objects, black frame around the lesion) or a low contrast. The second is the properties of the lesion itself : fuzzy borders, variation of the color of the lesion or the surrounding skin, and fragmentation of the lesion in multiple nodules. These conditions make the use of simple automated segmentation methods challenging without other processing stages.


%The image acquisition procedure should be described in sufficient
%detail.
%(2) The test image set should be selected randomly froma large and
%diverse image database.
%(3) The test image set should be large enough to ensure statistically
%valid conclusions.
%(4) The diagnostic distribution of the test image set should be
%stated.
%(5) Algorithms with reasonable computational requirements
%should be used.
%(6) The results should be evaluated using borders determined by
%multiple dermatologists.
%(7) The results should be compared to those of published border
%detection methods.
%(8) The border detection procedure should be described in sufficient
%detail.


\section{Pre-processing}
\subsection{Conversion to grayscale}

\paragraph{Choosing a color channel}

The segmentation performance is influence by the color space used. Although the literature commonly uses the blue channel from RGB color space as in~\cite{mendonca_comparison_2007}, a paper from Garnavi, Celebi and al~\cite{Garnavi2010} has shown that for a 
threshold-based approach the X channel from CIE-XYZ color space could perform better. 

To decide which of the blue or the X channel was the best for the ISBI dataset, a comparison of the segmentation performances was conducted. To have a better understanding of the influence of the color channel selection, this comparison also included red and green channels from RGB, luminance from HSV and the arithmetic averaging of the three RGB channels (meanRGB). 

Results for all channels are shown in table \ref{tab:color-channel} and with more details for the three best channels in figure \ref{fig:color-channel-otsu}. Despite one severe failure (please mind that the y axis ranges from 0.5 to 1), the blue channel is still the best one in average, followed by the green channel and meanRGB. Therefore, the blue channel was chosen for the conversion from RGB to grayscale image.
\paragraph{}

\begin{table}
	\caption{Color channel influence on thresholding results}
	\centering
	\begin{tabular}{l| *{6}{c}}	
	 channel & R & G & \textbf{B} & X & V & meanRGB \\ 
	\hline
	 Average dice & 0.78 & 0.87 & \textbf{0.89} & 0.85 & 0.78 & 0.87 \\ 
	 Average jaccard & 0.65 & 0.78 & \textbf{0.81} & 0.75 & 0.66 & 0.77 
	\end{tabular}
	\label{tab:color-channel}
\end{table}

\begin{figure}	[h]
	\includegraphics[width=0.9\linewidth]{../results/color-channel-influence/base-evaluation/channel-compare.png} 
	\caption{Dice index of the 3 best channels (B, G, and meanRGB)}
	\label{fig:color-channel-otsu}
\end{figure} 

\paragraph{Contrast enhancement}
We maximize the contrast with a linear contrast transformation by first subtracting the min value and then dividing the obtained image by its max value. This step is done after the removal of black border, so that only the area containing the skin and the lesion is taken into account for this transformation.


\begin{figure} [h]
\begin{subfigure}{0.32\linewidth}			
	\includegraphics[width=0.99\linewidth]{../results/color-channel-influence/orig.png}	  
	\caption{Original image}
	\label{fig:grayscale-orig}
\end{subfigure}
\begin{subfigure}{0.32\linewidth}			
	\includegraphics[width=0.99\linewidth]{../results/color-channel-influence/no_dyn_range.png}	  
	\caption{Blue channel selected}
	\label{fig:grayscale-no-dyn}
\end{subfigure}
\begin{subfigure}{0.32\linewidth}			
	\includegraphics[width=0.99\linewidth]{../results/color-channel-influence/dyn_range.png}	  
	\caption{Contrast enhancement}
	\label{fig:grayscale-dyn}
\end{subfigure}
	\caption{Conversion to grayscale}
	\label{fig:grayscale}
\end{figure}

\subsection{Hair removal}
\paragraph{} Dullrazor~\cite{Dullrazor1997} algorithm is a standard method for 
hair removal. It consists in the following steps:
\begin{enumerate}
	\item Locating dark hair with a grayscale morphological closing operation with 
	vertical, horizontal and diagonals structure elements on the three RGB channels. 
	We obtain the hair mask by thresholding the absolute difference with the 
	original image. 
	\item Denoising the hair mask and interpolating the hair pixels with neighbor 
	non-hair pixels. 
	\item Removing the remaining hair artifacts with an adapted median filter, only 
	applied on the pixels located in the enlarged hair regions
	(morphological dilatation of the hair mask).
\end{enumerate}

\begin{figure}
	\centering
	\includegraphics[width=0.32\linewidth]{../results/hair-removal/im_095} 
	\includegraphics[width=0.32\linewidth]{../results/hair-removal/hairmask_denoised_095} 
	\includegraphics[width=0.32\linewidth]{../results/hair-removal/imshaved_095} 
	\caption{Importance of hair removal for segmentation}
	\label{fig:dullrazor}
\end{figure}

Example in figure \ref{fig:dullrazor}.

The drawback of this method is that all parameters are adapted to be efficient on 512x486 pixels images, whereas the dataset used here contains high resolution images of different sizes (from 720x538 to 2814x2110). The images where therefore resized to the smallest resolution to reduce runtime of the segmentation algorithms and the parameters of the hair removal algorithm were adapted to fit this resolution.

\subsection{Black frame removal}



We see in figure \ref{fig:blackframe} how the performance increases with the removal of the black frame. Thresholding methods are the most affected since they are non local : the black corner of the image are the darker areas of the image and will therefore be selected as part of the lesion. One way of solving this issue is to perform a connected component analysis and select the ROI among the different clusters in postprocessing.

\begin{figure} [h]
	\centering
	\includegraphics[width=0.45\linewidth]{../results/blackframe/otsu_006_blackframe.png} 
	\includegraphics[width=0.45\linewidth]{../results/blackframe/otsu-segt-im-006.png} \\
	\includegraphics[width=0.45\linewidth]{../results/blackframe/otsu-noblack-036}
	\includegraphics[width=0.45\linewidth]{../results/blackframe/otsu-black-036}
	\caption{Importance of black frame removal}
	\label{fig:blackframe}
\end{figure} 
 However, this approach is not satisfying because firstly the lesion can be connected to the black frame (figure \ref{fig:blackframe} bottom) and secondly it can have multiple nodules so we can't just keep one "best" region according to any criterion. An additional reason to perform this step in preprocessing for the thresholding methods is to avoid any impact on the selection of the optimal threshold towards the black.


We can observe this effect on the figure \ref{fig:blackframe} : the ROI expands slightly on the right image compared to the left one. The black frame has been identified before the segmentation process, so that it is not taken into account when choosing the threshold.




\section{Post-processing:}
\paragraph{Morphological filling} This step consists in filling the holes that can appear inside the ROI with certain methods, such as thresholding or region merging. Our knowledge of the topology of the lesion is that they must be segmented in a unique connected component without hole. This is illustrated in figure \ref{fig:postproc-fill}.

\begin{figure}[h]
	\begin{subfigure}{0.32\linewidth}			
		\includegraphics[width=0.99\linewidth]{../results/postproc/otsu_nopost_174}	
		\caption{Segmented image}
		\label{fig:postproc-orig}
	\end{subfigure}
	\begin{subfigure}{0.32\linewidth}			
		\includegraphics[width=0.99\linewidth]{../results/postproc/otsu_filling_174}	  
		\caption{Morphological filling}
		\label{fig:postproc-fill}
	\end{subfigure}
	\begin{subfigure}{0.32\linewidth}			
		\includegraphics[width=0.99\linewidth]{../results/postproc/otsu_filling_CCA_174}
		\caption{CCA}
		\label{fig:postproc-CCA}
	\end{subfigure}
	\caption{Post processing steps}
	\label{fig:postproc}
\end{figure}

\paragraph{Connected Component Analysis} One of the major drawbacks of a thresholding is its non-local approach. Because of this, the segmentation result can be fragmented in several regions. A simple way to solve this issue would be to keep the biggest region, but it is not always the best choice, since lesion can be fragmented. The ideal result would be to merge the fragment by filling the space in between, but it is hard to distinguish a lesion fragment from a segmentation error caused by artifacts. Therefore, the choice made was to eliminate small regions (with an area more than 10 times smaller than the biggest region). This criterion was developed experimentally by trial and error on an image set distinct from the evaluation set. Result on an image can be seen in figure \ref{fig:postproc-CCA}.


\section{Adaptative thresholding}
\subsection{Method}
\paragraph{}
Thresholding is the simplest of the 3 methods reviewed here. It takes advantage of the fact that skin lesions are usually darker than the surrounding skin. Given a grayscale image, we canclassify pixels as being part of the region of interest (ROI) or of the 
background based on their intensities. However, using an absolute threshold for all images is not possible because of the color variability. 
\paragraph{} Otsu's algorithm ~\cite{Otsu1979}
gives a way to find an optimal threshold by seeing the histogram as a probability distribution, an choosing the threshold $k^*$ that maximizes the separability measure $\eta$ (equation \ref{eq:eta}) or equivalently the inter-class variance $\sigma_B^2$ because the total variance $\sigma_T^2$ remains constant for any chosen threshold. So the problem comes down to finding the threshold that maximizes $\sigma_B^2$ among the $L$ possible levels of gray as defined in the equation \ref{eq:optimthresh}. 

\begin{equation} \label{eq:eta}
\eta=\frac{\sigma_B^2}{\sigma_T^2} 
\end{equation}

with $ \sigma_B^2=\mathcal{P}(C_0)\mathcal{P}(C_1)(\mu_1-\mu_0)^2$ the interclass variance

\begin{equation} \label{eq:optimthresh}
  k^* = \argmax_{1<k<L} \sigma_B^2(k)   
\end{equation}

\subsection{Implementation}

\begin{figure}[h]
	\begin{subfigure}{0.49\linewidth}			
		\includegraphics[width=0.99\linewidth]{../results/otsu/histogram-thresh-sigma-002}	
		\caption{Histogram and interclass variance}
		\label{fig:otsu-hist}
	\end{subfigure}
	\begin{subfigure}{0.49\linewidth}			
		\includegraphics[width=0.99\linewidth]{../results/otsu/otsu-segt-im-002}	  
		\caption{Segmented image}
		\label{fig:otsu-segt-hist}
	\end{subfigure}
	\caption{Otsu's threshold}
	\label{fig:otsu-histogram}
\end{figure}

The implementation of this method is straightforward. We build the histogram of the image, and search the best threshold among the 254 possible values. For each threshold value, the histogram is divided into two clusters $C_0$ and $C_1$. We compute the associated inter-class variance using the equation \ref{eq:optimthresh} and keep the threshold corresponding to the maximum. The figure \ref{fig:otsu-histogram} shows the segmented image and its histogram (note that the black corners are not included thanks to the black frame removal). We can notice that despite a very flat evolution of the histogram, the chosen threshold can separate the two clusters in the middle which lead to the best separation of the clusters. 

However, it has been discussed~\cite{celebi_lesion_2009} that human operators tend to put the separation border on the outmost detectable pigmented pixel, whereas this threshold select an intermediary value. This can lead to under-segmentation. 



\subsection{Results} \label{results-otsu}

\paragraph{Metrics}
Two metrics are used for the evaluation of the results.

The dice index is calculated of the as shown in the equation \ref{eq:dice}:
\begin{equation} \label{eq:dice}
d=\frac{|I \cap J|}{1/2(|I| + |J|)} 
\end{equation}

The jaccard index is calculated as shown in the equation \ref{eq:jaccard}:
\begin{equation} \label{eq:jaccard}
j=\frac{|I \cap J|}{|I \cup J|} 
\end{equation}

This two indices are similar but jaccard is slightly more punishing, especially in cases where the segmented region and the ground truth have the same area but are not perfectly overlapped.
\begin{figure}[h]
	
	\includegraphics[width=0.32\linewidth]{../results/otsu/otsu-no-processing-000}
	\includegraphics[width=0.32\linewidth]{../results/otsu/otsu-no-processing-001}		\includegraphics[width=0.32\linewidth]{../results/otsu/otsu-no-processing-003} \\		\includegraphics[width=0.32\linewidth]{../results/otsu/otsu-no-processing-095}
	\includegraphics[width=0.32\linewidth]{../results/otsu/otsu-no-processing-036}
	\includegraphics[width=0.32\linewidth]{../results/otsu/otsu-no-processing-026} \\
	\includegraphics[width=0.32\linewidth]{../results/otsu/otsu-095}
	\includegraphics[width=0.32\linewidth]{../results/otsu/otsu-036}
	\includegraphics[width=0.32\linewidth]{../results/otsu/otsu-026}
	\caption{Thresholding segmentation examples}
	\caption*{First and second row : no processing - bottom row : with processing}
	\label{fig:otsu-ex}
\end{figure}

\paragraph{Results without processing} 
The two top rows of the figure \ref{fig:otsu-ex} show examples of segmentation results obtained without any pre- or post-processing other than the conversion from RGB to grayscale on the blue channel. As expected, this approach is very sensitive dark hair, black frame and fuzzy borders, but gives very good results on well contrasted lesions with sharp edges. On the entire dataset, the performance is :

Average dice index = 0.75

Average jaccard index = 0.65



\paragraph{Amelioration with pre- and post-processing} This increases the performances significantly :

Average dice index = 0.84

Average jaccard index = 0.75

The bottom rows of the figure \ref{fig:otsu-ex} help us to see how the segmentation changes with the additional processing stages. 

\begin{figure}[h]
	\centering
	\includegraphics[width=0.9\linewidth]{../results/otsu/melaVSnev}
	\caption{Adaptative thresholding, results for melanoma and nevus}
	\label{fig:otsu-melaVSnev}
\end{figure}

\paragraph{Melanoma and nevus} 
Results on the entire dataset are shown in figure \ref{fig:otsu-melaVSnev}, with a separation between melanoma and nevus classes. We can observe a significant difference of performance between images of benign and cancerous lesions : the results are better on images of nevus. An explanation for this effect could be the more complex structure of cancerous lesions, that often present more color variation and shape irregularities. 
\begin{figure}[h]
	\centering
	\includegraphics[width=0.40\linewidth]{../results/otsu/otsu-127}
	\caption{Critical failure for Otsu thresholding}
	\label{fig:otsu-127}
\end{figure}

The critical failure of the $19^{th}$ nevus image is caused by a very unusual lesion structure, shown in figure \ref{fig:otsu-127}. In this specific case, the blue channel is completely blind to the red variation and is not able do correctly detect the true borders.


\section{Region based segmentation}
\subsection{Method}
First, a simple region growing algorithm, but to slow and bad performances so SRM was used
\paragraph{ Statistical Region Merging~\cite{nock_statistical_2004} } This method has been 
used by Celebi and al~\cite{celebi_border_2008} to perform a fast and efficient 
segmentation of skin lesions. This approach consists in merging regions in a particular order, with a statistical criterion.

The image is considered as an observation of a theoretical image made of two regions : the lesion and the skin. We assume an homogeneity property of those regions, so that all pixels in a given region have the same statistical expectation. Each region can be described by a distinct probability distribution. 

SRM is based on two concepts : a merging predicate, described in equation \ref{eq:predicate} and an order two follow. This order is given by a similarity function $f$, which ensure that when merging two growing regions, all tests inside the regions have occurred. This results in a huge diminution of the runtime. A possible function is the radiometric difference as defined in equation \ref{eq:f}.

\begin{equation}
P(R,R')= 
\begin{cases}
\text{true} & \text{if } \forall a \in \lbrace \mathbf{R,G,B} \rbrace, |\bar{R}'_a - \bar{R}_a| \leq |\sqrt{b^2(R) + b^2(R')}|  \\
\text{false} & \text{otherwise}
\end{cases}
\label{eq:predicate}
\end{equation}
$$
b(R)=g \sqrt{\frac{1}{2Q|R|}\ln (6|I|^2R_{|R|})}
$$
\begin{equation}
f(p,p')=|p-p'| 
\label{eq:f}
\end{equation}
This method requires one parameter : Q. It is used to compute the threshold value $b$ of the merging predicate $P$. A high value for Q implies a lower tolerance for merging region. This will result in a more fragmented output but also more homogeneous regions. 

\paragraph{Why SRM?}
Compared to traditional region growing, the SRM algorithm has several advantages :

- No initialization required, which can have a heavy impact on the performances and the reproducibility.

- Fast

- Less sensitive to local inhomogeneities 

- Better merging order (the more similar region first) 

- Can produce more than two region : useful for fragmented lesions but that implies deciding the region to keep in the end.

\subsection{Implementation}
The implementation follows~\cite{celebi_border_2008} and consists in the following steps :

\begin{enumerate}
	\item Preprocessing stages (conversion to grayscale, contrast enhancement, black frame detection, hair removal)
	\item Adapted median smoothing of size $n=floor\left( 5\sqrt{(M/768)(N/512)}\right)$ for better region homogeneities. The size of the mask is adapted to the size of the image given the observation that n=5 is a good choice for images of size 768x512.
	\item Pixel pairing in 4-connectivity and sorting by increasing order of $f(p,p')$
	\item Traversing the order once and perform the merging test for any pair of pixels where $R(p)\neq R(p')$. Merge if it returns true.
	\item User input : selection of a skin patch.
	\item Classification of the region between lesion and skin by comparing their mean value to the skin patch.
	\item Postprocessing stages 
\end{enumerate}

The steps 3 and 4 correspond to the actual SRM algorithm. Since it produces more than two regions, as shown in figure \ref{fig:srm-reg}, we use a skin patch to distinguish skin regions from lesion.~\cite{celebi_border_2008} does it automatically by choosing the skin patch in the corner of the image, but it was not possible with my data since there is some times no location in the image on which we are sure to find skin (the corners are sometimes covered by the black frame). Therefore, we used a input from the user to select a patch of skin. 

Then, we compute the mean value of this patch, an we reject as skin all region with a mean value closer than 60 to the skin mean value. The result of the segmentation obtained can be seen in figure \ref{fig:srm-seg}.



\begin{figure}[h]
	\begin{subfigure}{0.329\linewidth}			
		\includegraphics[width=0.99\linewidth]{../results/srm/im-181}	
		\caption{Original image\\ (type: nevus)}
		\label{fig:srm-steps-orig}
	\end{subfigure}
	\begin{subfigure}{0.329\linewidth}			
		\includegraphics[width=0.99\linewidth]{../results/srm/srm-181}	  
		\caption{SRM output (regions replaced by the mean values)}
		\label{fig:srm-reg}
	\end{subfigure}
	\begin{subfigure}{0.329\linewidth}			
		\includegraphics[width=0.99\linewidth]{../results/srm/srm-segt-181}
		\caption{Segmentation (red) and ground truth (green)}
		\label{fig:srm-seg}
	\end{subfigure}
	\caption{Post processing steps}
	\label{fig:srm-steps}
\end{figure}


\subsection{Results}

Average dice index = 0.84\\
Average jaccard index = 0.74

\begin{figure}
	\centering
	\includegraphics[width=0.9\linewidth]{../results/srm/dice-jaccard-srm-2}
	\caption{Statistical Region Merging : results on melanoma and nevus}
	\label{fig:srm-melaVSnev}
\end{figure}

Again, we can observe in figure \ref{fig:srm-melaVSnev} better performances on nevus images. The nevus image number 19, discussed earlier, is also challenging for this method because it is very fragmented and therefore get separated into different regions.

The weak point of this method is the region selection. Instead of simply comparing the mean value of the skin patch to those of the regions, we perform a better texture analysis by including colors, or variance. Another approach could be to select a lesion patch instead of a skin patch and choose similar region. 

\section{Parametric active contours}
\subsection{Method}
\paragraph{} The third method studied here takes the approach of active contour,  Distance Regularized Level Set Evolution \cite{li2010distance} 
The contour is described as the intersection of a higher dimension Level Set Function (LSF) with the level 0, as expressed in equation \ref{eq:phi}.
\begin{equation}
\phi_k(x,y)=0
\label{eq:phi}
\end{equation}

The evolution of the curve is then described in \ref{eq:PDE} by the following partial differential equation, or level set evolution equation :
\begin{equation}
\frac{\partial \phi}{\partial t} = F|\nabla\phi|
\label{eq:PDE}
\end{equation}

To maintain a stable evolution and an accurate numerical computation, we need to keep the LSF smooth, not too steep or too flat. This property is satisfied in the signed distance function where $|\nabla\phi|=1$ (equivalent to a 45 degree angle of the 3D surface in our case). We can see an illustration of the distance function  initialized with 3 points in figure \ref{fig:dist-LSF}

\begin{figure}
\centering
\includegraphics[width=0.7\linewidth]{../results/level_set/dist-LSF}
\caption{Distance Function}
\label{fig:dist-LSF}
\end{figure}

The distance regularization proposed in~\cite{li2010distance} helps maintaining this property. It uses an energy functional $\mathcal{E}$ defined in \ref{eq:energy}
\begin{equation}
\mathcal{E}(\phi)=\mu\mathcal{R}_p(\phi)+\mathcal{E}_{ext}(\phi)
\label{eq:energy}
\end{equation}
Where $\mu>0$, $\mathcal{E}_{ext}$ is the external energy derived from the gradient of the image, and $\mathcal{R}_p$ is the distance regularization term defined in 
\begin{equation}
\mathcal{R}_p(\phi) \stackrel{\Delta}{=} \int_{\Omega}^{}p(|\nabla\phi|)dx
\end{equation}
where p is a potential function $p : [0,\infty) \rightarrow R$

To avoid some side effects,~\cite{li2010distance} uses a double-well potential $p=p_2$ that has two minimum points at $s=1$ and $s=0$. This function is explicitly defined in \ref{eq:p}
\begin{equation}
p_2(s)= 
\begin{cases}
\frac{1}{2 \pi} \sin(2\pi s) \text{ if } s \leq 1 \\
\frac{1}{2} (s-1)^2 \text{ if } s \geq 1
\end{cases}
\label{eq:p}
\end{equation}

Finally, the Distance Regularized Level Set Evolution (DRLSE) can be expressed as in \ref{eq:DRLSE}. This equation is derived from the variational formulation \ref{eq:energy}.
\begin{equation}
\frac{\partial \phi}{\partial t} = \mu \cdot \text{div} (d_p(\nabla\phi)\nabla\phi) - \frac{\partial \mathcal{E}_ext}{\partial\phi} 
\label{eq:DRLSE}
\end{equation}

\subsection{Implementation}
\subsubsection*{Discretization}

The DRLSE in \ref{eq:DRLSE} is implemented with a finite difference scheme where spatial derivatives are replaced by central difference with a fixed step of $\Delta x = \Delta y = 1$ and the temporal derivative is approximated by the forward difference. We obtain the following equation 

\begin{equation}
\phi_{i,j}^{k+1}=\phi_{i,j}^k + \Delta t L(\phi_{i,j}^k), \quad \text{with } k=0,1,2,... 
\end{equation}

For the segmentation, the edge indicator is  given by the function defined in \ref{eq:edgefunc}, where $G_\sigma$ is a gaussian kernel of standard deviation $\sigma$ to reduce noise. g takes small values on edges.
\begin{equation}
g \stackrel{\Delta}{=}\frac{1}{1+\nabla G_\sigma \ast I|^2}
\label{eq:edgefunc}
\end{equation}

The energy can then be expressed as \ref{eq:energy-impl} :
\begin{equation}
\mathcal{E}(\phi)= \mu\mathcal{R}_p(\phi) + \lambda \mathcal{L}_g(\phi) + \alpha\mathcal{A}_g(\phi)
\label{eq:energy-impl}
\end{equation}
$$\mathcal{L}_g(\phi) \stackrel{\Delta}{=}\int_{\omega}g\cdot\delta (\phi)\nabla\phi dx $$
$$\mathcal{A}_g(\phi)\stackrel{\Delta}{=}\int_{\omega}g\cdot H(-\phi)dx$$

$\delta$ is the Dirac function, approximated by the equation \ref{eq:dirac}, so that $\mathcal{L}_g(\phi)$ computes the integral of $g$ along the line where $\phi = 0$, that is the actual contour used for segmenting the image. This integral is minimized when this contour is located at the boundaries of the lesion, where $g$ takes its smallest values. This component is weighted by the parameter $\lambda$.
\begin{equation}
\delta_\epsilon(x)= 
\begin{cases}
\frac{1}{2x}[1+\cos(\frac{\pi x}{\epsilon})], \quad if \quad |x| \leq \epsilon \\
0 \quad if \quad |x| > \epsilon 
\end{cases}
\label{eq:dirac}
\end{equation}

H is the Heaviside function, approximated by the equation \ref{eq:heaviside}, so that $\mathcal{A}_g(\phi)$ computes a weighted area of the region where $\phi(x)<0$. It is used to force the contour to grow or to shrink by changing the value of $\alpha$. Since this paper gives negative values inside the contour and positive values outside, we take positive values of $\alpha$ so that the contour can shrink, with an initial contour placed outside of the lesion. The presence of $g$ in this energy term will slow down the shrinking when we arrive at the boundaries of the lesion.


The decision of having a contour initialized outside of the lesion and a shrinking evolution was mainly made to speed up the algorithm : after the initialization, the image was cropped to the bounding box of the initial contour, as we know that the lesion is contained in it.

\begin{equation}
H_\epsilon(x)= 
\begin{cases}
\frac{1}{2}[1+\frac{x}{\epsilon}+\frac{1}{\pi}\sin(\frac{\pi x}{\epsilon})], \quad if \quad |x| \leq \epsilon \\
1 \quad if \quad |x| > \epsilon \\
0 \quad if \quad |x| < -\epsilon \\
\end{cases}
\label{eq:heaviside}
\end{equation}

\subsubsection*{Algorithm}
\begin{itemize}
	\item Initialization of $\phi$ with $\phi_0$ provided through user input (polyline). 
	\item Update the LSF : $ \phi_{i,j}^{k+1}=\phi_{i,j}^k + \tau L(\phi_{i,j}^k)$
	\item Assign values to new pixels 
	\item Test the termination : stop if the zero crossing points stop varying or $k$ exceed a maximum iteration number, else go to step 2.
\end{itemize}

\subsubsection*{Parameters}
The DRLSE algorithm requires several parameters listed below, and proved to be very sensitive the values used. I managed to obtained good results using the following values:

Timestep: $\tau=1$,

Distance regularization: $mu=0.2/\tau= 0.2$, 

Length term $\mathcal{L}_g(\phi)$ coefficient: $\lambda=1$,

Area term $\mathcal{A}_g(\phi)$ coefficient: $\alpha = 5$,

Width of the dirac function: $\epsilon=1.5$,

Maximum number of iterations: $n_{iter,max} = 100$ 

\begin{figure}[h]
	\centering
	\begin{subfigure}{0.49\linewidth}			
		\includegraphics[width=0.99\linewidth]{../results/level_set/im001}
		\caption{dice: 0.88, jaccard: 0.79}
		\label{fig:LS-res-001}
	\end{subfigure}
	\begin{subfigure}{0.49\linewidth}			
		\includegraphics[width=0.99\linewidth]{../results/level_set/im127}
		\caption{dice: 0.88, jaccard: 0.78}
		\label{fig:LS-res-127}
	\end{subfigure}
	\begin{subfigure}{0.49\linewidth}			
		\includegraphics[width=0.99\linewidth]{../results/level_set/im043}
		\caption{dice: 0.92, jaccard: 0.85}
		\label{fig:LS-res-043}
	\end{subfigure}
	\begin{subfigure}{0.49\linewidth}			
		\includegraphics[width=0.99\linewidth]{../results/level_set/im004}
		\caption{dice: 0.97, jaccard: 0.94}
		\label{fig:LS-res-004}
	\end{subfigure}
	\caption{level set}
	\label{fig:level-set-results}
\end{figure}

\subsection{Results}
Examples of results are shown in figure \ref{fig:level-set-results}. We used only the conversion to grayscale and the hair removal preprocessing (no black frame removal). As we can see, the results are good, especially on difficult images such as \ref{fig:LS-res-127} or \ref{fig:LS-res-004}, with a dice index of 0.88 and 0.97 respectively, where the previous method were unable to give an acceptable result. However, some "easy" images are oversegmented as illustrated in \ref{fig:LS-res-001}, but this can probably be enhanced by a two stages evolution as proposed in~\cite{li2010distance} : after the convergence of the evolution, they et the area coefficient to 0 and compute additional iterations to refine the contour and get closer to the true edges. 

Another way to improve my implementation would be to implement a narrow band computation, so that only a small region around the current contour gets updated on each step, to speed up the algorithm, since despite the image cropping, the evolution is still not very fast. This amelioration was however not implemented and the complete dataset evaluation was not made for this method. Please note that even with a fast algorithm, this method would remain the slowest of the three compared here because of the time used for user input. 

\section{Comparison}

\subsection{Perfomances}

As we have seen, the DRLSE provides the best results most of the times, and is especially reliable for difficult images, but its parameters are hard to tune and the segmentation process is slow due to the user input, that must surround the lesion closely enough.

To compare the two other algorithms, we can refer to the figure \ref{fig:otsu-srm-compare} that overlaps the results from the thresholding method and SRM on the dataset. Although they can differ on certain images, the average performance is the same.

The table \ref{tab:method-compare} summarize the advantages and drawbacks of the three methods studied for this project.

\begin{figure}[h]
\centering
\includegraphics[width=0.7\linewidth]{../results/comparison/otsu-srm-compare}
\caption{Otsu - SRM comparison : dice index\\ The two methods have the same average dice value of 0.84 on the dataset}
\label{fig:otsu-srm-compare}
\end{figure}

\begin{tabular}{|c|c|c|c|}
	\hline
	 Method & Thresholding & Region & Level Set \\ \hline 
	\multirow{4}{*}{ Advantages} & simple & simple & Using prior knowledge \\ 
	& unsupervised & fast & precise segmentation \\
	& fast & & No critical failure\\
	& no parameter & & \\ \hline 
	\multirow{4}{*}{Drawbacks} & lot of processing & Semi-automated & Parameters hard to tune \\ 
	& & not better than thresholding & slow \\
	& & & semi-automated \\
	& & & sensitive to initialization \\ \hline 
	\label{tab:method-compare}
\end{tabular} 

The thresholding have roughly the same performances as the SRM algorithm, and is fully automated. Therefore, it may constitute a better choice for lesion segmentation unless better and more adapted processing can improve the SRM results.

On the other and, the Level Set approach is the best one on difficult images but also the slowest. So it could be interesting to have a choice between the thresholding and Level Set algorithm to provide the best results. A user could review the segmentation results of the thresholding and use Level Set as a semi-automated method on difficult images only.

\subsection{Choosing the right method}

\begin{figure}[h]
	\centering
	\includegraphics[width=0.6\linewidth]{../results/selection-criterion/otsu-dice-jaccard-eta-plot}
	\caption{$\eta$ (green), dice (red)\\ Correlation coefficient : R($\eta$, dice)=0.50 }
	\label{fig:eta-correlation}
\end{figure}

An interesting development of this comparison would be to have an efficient and easily computable criterion to choose automatically the adapted method given a particular image, so that the operator would not have to review all images. In this section we will show that Otsu's separability measure could make a simple, but not perfect, criterion.

\subsubsection*{Separability criterion}



To compute the threshold with Otsu's method, we optimize a separability measure $\eta$. We investigated whether there were a correlation between this value and the evaluation metrics, so that it could be used to evaluate the performance of the thresholding algorithm. The results are shown in figure \ref{fig:eta-correlation} and it appears that $\eta$ is correlated to the evaluation metrics with a correlation coefficient of 0.5.

To test this criterion, we determined on a training set a threshold for eta that would ensure a good performance (dice>0.7) for the thresholding method. That could help us to automatically detect good from bad performances on real data and for instance switch to a semi-automatic method in that case. We also wanted to control how many images would have to be rejected. Given the algorithm performances described in section \ref{results-otsu}, we should only drop the 7/42 ()16.7\%) of the dataset where the dice index was lower than 0.7.  
\begin{figure}[h]
	\centering
	\includegraphics[width=0.6\linewidth]{../results/selection-criterion/eta-dice-drop}
	\caption{Evolution of the performance when dropping bad results}{Red curve :  dropping images with the lowest separability metric $\eta$\\ Blue curve : dropping images with the actual worst dice value \\ Dotted lines : percentage of image rejected to ensure $dice > 0.7$}
	\label{fig:eta-dice-drop}
\end{figure}

The figure \ref{fig:eta-dice-drop} shows the evolution of the lowest performance while we iteratively drop the image with the smallest $\eta$ value, ie what we believe to be the worst performance. We compared that to the evolution of the worst performance while dropping the image with the smallest dice index, ie the actual worst performance. To ensure a dice index higher than 0.7 on this training et, we would have to reject all images with $\eta < 0.8$, which represent about 47\% of the set. This rejection rate is high, but if we lower the $\eta$ threshold to 0.7, decreasing the rejection rate to a more acceptable 11\%, the lowest dice index accepted as "good" comes down to 0.55. 

Therefore, the selected threshold for $\eta$ is 0.8.

To test how reliable this technique is, we evaluated this 0.8 threshold on a test set of 50 images. The figure \ref{fig:test-criterion-accepted} shows that the criterion ensured indeed a dice index above 0.7 (only one outlier at 0.68), at the cost of 42\% (21/50) rejection rate.



\begin{figure}[h]
	\centering
	\includegraphics[width=0.6\linewidth]{../results/selection-criterion/test-dice-eta-plot}
	\includegraphics[width=0.6\linewidth]{../results/selection-criterion/test-dice-eta-accepted}
	\caption{Test of the criterion - dice : squares, $\eta$ : stars, rejected : black }
	\label{fig:test-criterion-accepted}
\end{figure}

\subsection*{Ground Truth quality}
The ground truth used was not perfect: it is hard to produce segmentation gold standard, especially in lesion segmentation because of fuzzy borders, color and shape variability and other defaults. In this dataset from ISIC, two different methods of manual segmentation were used and our algorithms were not easily able to perform well for both.

\section*{Conclusion}

We have shown in this project that the adaptative thresholding can give good result when associated with pre- and post-processing. The SRM method that we implemented would need some improvement to justify the need of a user interaction in the process by a real increase of performance, compared to the thresholding. Level Set is the most reliable method for difficult images, but require tuning many parameters and we have probably not chosen the optimal values, but the drawback is a high runtime and a high cost in terms of user interaction. Therefore it should be only used on difficult images.

We propose a criterion to automatically detect such images using the separability measure used in Otsu's optimal threshold selection. This criterion as a high sensitivity but a lw specificity, so it comes with a high cost of wrongly rejected images. However, a user would only need a short time to flag a rejected image as "acceptable".

\bibliographystyle{plain}
\bibliography{PRIM-rapport}

\end{document}
